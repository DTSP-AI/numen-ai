"""
Memory Manager - Thread + Semantic Memory on Supabase

Implements dual-layer memory:
1. ThreadMemory (short-term): Session-scoped rolling context
2. SemanticMemory (long-term): Embedded chunks with vector similarity retrieval
"""

import logging
import json
from typing import List, Dict, Any, Optional
from datetime import datetime
import uuid

from database import get_pg_pool
from services.embeddings import embeddings_service

logger = logging.getLogger(__name__)


class MemoryManager:
    """
    Unified memory manager for agent interactions

    Tables:
    - thread_memory: Short-term session context (turns, summaries, facts)
    - semantic_memory: Long-term embedded chunks with vector search
    """

    def __init__(self):
        self.pool = None

    async def initialize(self):
        """Initialize database tables if not present"""
        self.pool = get_pg_pool()

        try:
            async with self.pool.acquire() as conn:
                # Enable pgvector extension
                await conn.execute("CREATE EXTENSION IF NOT EXISTS vector")

                # Create thread_memory table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS thread_memory (
                        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                        user_id TEXT NOT NULL,
                        agent_id UUID,
                        session_id UUID,
                        turn_index INTEGER NOT NULL,
                        key TEXT NOT NULL,
                        value JSONB NOT NULL,
                        created_at TIMESTAMP DEFAULT NOW()
                    )
                """)

                # Index for fast session lookups
                await conn.execute("""
                    CREATE INDEX IF NOT EXISTS idx_thread_memory_session
                    ON thread_memory(session_id, turn_index)
                """)

                # Create semantic_memory table
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS semantic_memory (
                        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                        user_id TEXT NOT NULL,
                        agent_id UUID,
                        session_id UUID,
                        content TEXT NOT NULL,
                        embedding VECTOR(1536),
                        meta JSONB,
                        created_at TIMESTAMP DEFAULT NOW()
                    )
                """)

                # TODO: Add pgvector index when embeddings are active
                # await conn.execute("""
                #     CREATE INDEX IF NOT EXISTS idx_semantic_memory_embedding
                #     ON semantic_memory USING ivfflat (embedding vector_cosine_ops)
                #     WITH (lists = 100)
                # """)

                logger.info("âœ… Memory tables initialized")

        except Exception as e:
            logger.error(f"Failed to initialize memory tables: {str(e)}")
            raise

    async def record_turn(
        self,
        user_id: str,
        agent_id: str,
        session_id: str,
        turn_index: int,
        key: str,
        value_dict: dict
    ):
        """
        Record a turn in thread memory

        Args:
            user_id: User ID
            agent_id: Agent ID
            session_id: Session ID
            turn_index: Turn number in conversation
            key: Memory key (e.g., "user_input", "agent_response", "summary")
            value_dict: JSON-serializable data
        """
        try:
            async with self.pool.acquire() as conn:
                await conn.execute("""
                    INSERT INTO thread_memory (user_id, agent_id, session_id, turn_index, key, value)
                    VALUES ($1, $2::uuid, $3::uuid, $4, $5, $6)
                """,
                    user_id,
                    agent_id,
                    session_id,
                    turn_index,
                    key,
                    json.dumps(value_dict)
                )

            logger.debug(f"Recorded turn {turn_index} for session {session_id}")

        except Exception as e:
            logger.error(f"Failed to record turn: {str(e)}")
            raise

    async def summarize_and_store(
        self,
        session_id: str,
        text: str
    ):
        """
        Store summary in thread memory

        Args:
            session_id: Session ID
            text: Summary text
        """
        try:
            # Get session info
            async with self.pool.acquire() as conn:
                session = await conn.fetchrow("""
                    SELECT user_id, agent_id FROM sessions WHERE id = $1::uuid
                """, session_id)

                if not session:
                    logger.warning(f"Session {session_id} not found for summary")
                    return

                # Get latest turn index
                latest_turn = await conn.fetchval("""
                    SELECT COALESCE(MAX(turn_index), -1) FROM thread_memory
                    WHERE session_id = $1::uuid
                """, session_id)

                # Record summary
                await conn.execute("""
                    INSERT INTO thread_memory (user_id, agent_id, session_id, turn_index, key, value)
                    VALUES ($1, $2::uuid, $3::uuid, $4, 'summary', $5)
                """,
                    session["user_id"],
                    session["agent_id"],
                    session_id,
                    latest_turn + 1,
                    json.dumps({"text": text})
                )

            logger.info(f"Stored summary for session {session_id}")

        except Exception as e:
            logger.error(f"Failed to store summary: {str(e)}")
            raise

    async def embed_and_upsert(
        self,
        user_id: str,
        agent_id: str,
        session_id: str,
        content: str,
        meta: Optional[dict] = None
    ):
        """
        Embed content and store in semantic memory

        NOTE: Embedding generation is TODO. Currently stores with null embedding.

        Args:
            user_id: User ID
            agent_id: Agent ID
            session_id: Session ID
            content: Content to embed
            meta: Metadata dict
        """
        try:
            # Generate embedding with OpenAI
            embedding = await embeddings_service.generate_embedding(content)

            async with self.pool.acquire() as conn:
                await conn.execute("""
                    INSERT INTO semantic_memory (user_id, agent_id, session_id, content, embedding, meta)
                    VALUES ($1, $2::uuid, $3::uuid, $4, $5, $6)
                """,
                    user_id,
                    agent_id,
                    session_id,
                    content,
                    embedding,
                    json.dumps(meta or {})
                )

            logger.info(f"Stored semantic memory for session {session_id}")

        except Exception as e:
            logger.error(f"Failed to store semantic memory: {str(e)}")
            raise

    async def similar(
        self,
        user_id: str,
        agent_id: str,
        session_id: str,
        query: str,
        k: int = 8
    ) -> List[Dict[str, Any]]:
        """
        Search for similar content in semantic memory

        NOTE: Vector search is TODO. Currently returns recent content.

        Args:
            user_id: User ID
            agent_id: Agent ID
            session_id: Session ID (optional filter)
            query: Query text
            k: Number of results

        Returns:
            List of {content, meta, score} dicts
        """
        try:
            # Generate query embedding
            query_embedding = await embeddings_service.generate_embedding(query_text)

            async with self.pool.acquire() as conn:
                # If embedding available, use vector similarity search
                if query_embedding:
                    rows = await conn.fetch("""
                        SELECT content, meta,
                               1 - (embedding <=> $1::vector) as similarity_score
                        FROM semantic_memory
                        WHERE user_id = $2
                          AND (agent_id = $3::uuid OR agent_id IS NULL)
                          AND (session_id = $4::uuid OR $4 IS NULL)
                          AND embedding IS NOT NULL
                        ORDER BY embedding <=> $1::vector
                        LIMIT $5
                    """,
                        query_embedding,
                        user_id,
                        agent_id,
                        session_id if session_id else None,
                        k
                    )
                else:
                    # Fallback: return recent content if no embedding
                    rows = await conn.fetch("""
                        SELECT content, meta, created_at
                        FROM semantic_memory
                        WHERE user_id = $1
                          AND (agent_id = $2::uuid OR agent_id IS NULL)
                          AND (session_id = $3::uuid OR $3 IS NULL)
                        ORDER BY created_at DESC
                        LIMIT $4
                    """,
                        user_id,
                        agent_id,
                        session_id if session_id else None,
                        k
                    )

            results = [
                {
                    "content": row["content"],
                    "meta": row["meta"],
                    "score": row.get("similarity_score", 1.0)
                }
                for row in rows
            ]

            logger.debug(f"Retrieved {len(results)} semantic memories")
            return results

        except Exception as e:
            logger.error(f"Failed to search semantic memory: {str(e)}")
            return []

    async def context_for_planning(
        self,
        user_id: str,
        agent_id: str,
        session_id: str
    ) -> Dict[str, Any]:
        """
        Get combined context for planning (thread tail + semantic matches)

        Args:
            user_id: User ID
            agent_id: Agent ID
            session_id: Session ID

        Returns:
            Dict with {thread_tail, semantic_memories}
        """
        try:
            # Get last 10 turns from thread memory
            async with self.pool.acquire() as conn:
                thread_rows = await conn.fetch("""
                    SELECT turn_index, key, value, created_at
                    FROM thread_memory
                    WHERE session_id = $1::uuid
                    ORDER BY turn_index DESC
                    LIMIT 10
                """, session_id)

            thread_tail = [
                {
                    "turn_index": row["turn_index"],
                    "key": row["key"],
                    "value": row["value"],
                    "created_at": row["created_at"].isoformat()
                }
                for row in reversed(list(thread_rows))  # Reverse to chronological order
            ]

            # Get top-k semantic memories
            semantic_memories = await self.similar(
                user_id=user_id,
                agent_id=agent_id,
                session_id=session_id,
                query="user goals and constraints",
                k=8
            )

            return {
                "thread_tail": thread_tail,
                "semantic_memories": semantic_memories
            }

        except Exception as e:
            logger.error(f"Failed to build planning context: {str(e)}")
            return {"thread_tail": [], "semantic_memories": []}
